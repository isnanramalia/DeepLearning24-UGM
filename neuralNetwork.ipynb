{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
      "0  13300000  7420         4          2        3      yes        no       no   \n",
      "1  12250000  8960         4          4        4      yes        no       no   \n",
      "2  12250000  9960         3          2        2      yes        no      yes   \n",
      "3  12215000  7500         4          2        2      yes        no      yes   \n",
      "4  11410000  7420         4          1        2      yes       yes      yes   \n",
      "\n",
      "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
      "0              no             yes        2      yes        furnished  \n",
      "1              no             yes        3       no        furnished  \n",
      "2              no              no        2      yes   semi-furnished  \n",
      "3              no             yes        3      yes        furnished  \n",
      "4              no             yes        2       no        furnished  \n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load dataset\n",
    "data = pd.read_csv('Housing.csv')\n",
    "\n",
    "# spoiler data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      price  area  bedrooms  bathrooms  stories  mainroad  guestroom  \\\n",
      "0  13300000  7420         4          2        3         1          0   \n",
      "1  12250000  8960         4          4        4         1          0   \n",
      "2  12250000  9960         3          2        2         1          0   \n",
      "3  12215000  7500         4          2        2         1          0   \n",
      "4  11410000  7420         4          1        2         1          1   \n",
      "\n",
      "   basement  hotwaterheating  airconditioning  parking  prefarea  \\\n",
      "0         0                0                1        2         1   \n",
      "1         0                0                1        3         0   \n",
      "2         1                0                0        2         1   \n",
      "3         1                0                1        3         1   \n",
      "4         1                0                1        2         0   \n",
      "\n",
      "   furnishingstatus  \n",
      "0                 0  \n",
      "1                 0  \n",
      "2                 1  \n",
      "3                 0  \n",
      "4                 0  \n"
     ]
    }
   ],
   "source": [
    "# konversi kolom categorical jd numerik\n",
    "data['mainroad'] = data['mainroad'].map({'yes': 1, 'no': 0})\n",
    "data['guestroom'] = data['guestroom'].map({'yes': 1, 'no': 0})\n",
    "data['basement'] = data['basement'].map({'yes': 1, 'no': 0})\n",
    "data['hotwaterheating'] = data['hotwaterheating'].map({'yes': 1, 'no': 0})\n",
    "data['airconditioning'] = data['airconditioning'].map({'yes': 1, 'no': 0})\n",
    "data['prefarea'] = data['prefarea'].map({'yes': 1, 'no': 0})\n",
    "# data['furnishingstatus'] = data['furnishingstatus'].map({'furnished': 2, 'semi-furnished': 1, 'unfurnished': 0})\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "data['furnishingstatus']=LabelEncoder().fit_transform(data['furnishingstatus'])\n",
    "data.head()\n",
    "\n",
    "# # Separate features and target\n",
    "# X = data.drop('price', axis=1)\n",
    "# y = data['price']\n",
    "\n",
    "# spoiler dataset\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, random_state=32, test_size=0.2):\n",
    "\n",
    "    n_samples = X.shape[0]\n",
    "    np.random.seed(random_state)\n",
    "    shuffled_indices = np.random.permutation(np.arange(n_samples))\n",
    "\n",
    "    test_size = int(n_samples * test_size)\n",
    "\n",
    "    test_indices = shuffled_indices[:test_size]\n",
    "    train_indices = shuffled_indices[test_size:]\n",
    "\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(X):\n",
    "\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "\n",
    "    # normalisasi data\n",
    "    X = (X - mean) / std\n",
    "    return X\n",
    "\n",
    "def scale(y):\n",
    "    # Calculate the mean and standard deviation of each feature\n",
    "    mean = np.mean(y, axis=0)\n",
    "    std = np.std(y, axis=0)\n",
    "\n",
    "    # normalisasi data\n",
    "    y = (y - mean) / std\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['area', 'bedrooms', 'bathrooms', 'stories', 'mainroad', 'guestroom', 'airconditioning', 'parking', 'prefarea', 'furnishingstatus']\n"
     ]
    }
   ],
   "source": [
    "corr = data.corr()\n",
    "cor_target = abs(corr[\"price\"])\n",
    "\n",
    "relevant_features = cor_target[cor_target>0.2]\n",
    "\n",
    "names = [index for index, value in relevant_features.items()]\n",
    "\n",
    "names.remove('price')\n",
    "\n",
    "# Display the results\n",
    "print(names)\n",
    "X = data[names].values\n",
    "y = data['price'].values\n",
    "\n",
    "X = scale(X)\n",
    "y = scale(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train(X, y, test_size = 0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    A = np.maximum(0,Z)\n",
    "    cache = Z \n",
    "    return A, cache\n",
    "z = np.linspace(-12, 12, 200)\n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "def linear(Z):\n",
    "    A = Z  \n",
    "    cache = Z  \n",
    "    return A, cache\n",
    "\n",
    "def linear_backward(dA, cache):\n",
    "    dZ = dA  \n",
    "    return dZ\n",
    "\n",
    "def sigmoid(Z):\n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    return A, cache\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "    Z = cache\n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desain Arsitektur *Neural Network*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralFunction:\n",
    "    def __init__(self, layer_dimensions=[12, 32, 1], learning_rate=0.01, gd_type='batch', mini_batch_size=64):\n",
    "        self.layer_dimensions = layer_dimensions\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gd_type = gd_type\n",
    "        self.mini_batch_size = mini_batch_size\n",
    "        \n",
    "    def initialize_parameters(self):\n",
    "        np.random.seed(3)\n",
    "        self.n_layers =  len(self.layer_dimensions)\n",
    "        for l in range(1, self.n_layers):\n",
    "            vars(self)[f'W{l}'] = np.random.randn(self.layer_dimensions[l], self.layer_dimensions[l-1]) * 0.01\n",
    "            vars(self)[f'b{l}'] = np.zeros((self.layer_dimensions[l], 1))\n",
    "    \n",
    "    def _linear_forward(self, A, W, b):\n",
    "    \n",
    "        Z = np.dot(W,A) + b\n",
    "\n",
    "        cache = (A, W, b)\n",
    "        return Z, cache\n",
    "    \n",
    "    def _forward_prop(self,A_prev ,W ,b , activation):\n",
    "        if activation == \"linear\":\n",
    "            Z, linear_cache = self._linear_forward(A_prev, W, b)\n",
    "            A, activation_cache = linear(Z) \n",
    "        elif activation == \"relu\":\n",
    "            Z, linear_cache = self._linear_forward(A_prev, W, b) \n",
    "            A, activation_cache = relu(Z) \n",
    "        cache = (linear_cache, activation_cache)\n",
    "        return A, cache\n",
    "    \n",
    "    def forward_prop(self, X):\n",
    "        caches = []\n",
    "        A = X\n",
    "        L =  self.n_layers -1\n",
    "        for l in range(1, L):\n",
    "            A_prev = A \n",
    "            A, cache = self._forward_prop(A_prev, vars(self)['W' + str(l)], vars(self)['b' + str(l)], \"relu\")\n",
    "            caches.append(cache)\n",
    "        predictions, cache = self._forward_prop(A, vars(self)['W' + str(L)], vars(self)['b' + str(L)], \"linear\")\n",
    "        caches.append(cache)\n",
    "\n",
    "        return predictions, caches\n",
    "        \n",
    "    def _linear_backward(self, dZ, cache):\n",
    "        A_prev, W, b = cache\n",
    "        m = A_prev.shape[1]\n",
    "        dW = (1/m) * np.dot(dZ, A_prev.T)\n",
    "        db = (1/m) * np.sum(dZ, axis=1, keepdims=True)\n",
    "        dA_prev = np.dot(W.T,dZ)\n",
    "        return dA_prev, dW, db\n",
    "    \n",
    "            \n",
    "    def _back_prop(self, dA, cache, activation):\n",
    "        linear_cache, activation_cache = cache\n",
    "        if activation == \"relu\":\n",
    "            dZ = relu_backward(dA, activation_cache)\n",
    "\n",
    "        elif activation == \"linear\":\n",
    "            dZ = linear_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = self._linear_backward(dZ, linear_cache)\n",
    "        return dA_prev, dW, db\n",
    "\n",
    "    def back_prop(self, predictions, Y, caches):\n",
    "    \n",
    "        L =  self.n_layers - 1\n",
    "        m = predictions.shape[0]\n",
    "        Y = Y.reshape(predictions.shape) \n",
    "        dAL = - (np.divide(Y, predictions+1e-9) - np.divide(1 - Y, 1 - predictions+1e-9))\n",
    "        current_cache = caches[L-1] \n",
    "        vars(self)[f'dA{L-1}'], vars(self)[f'dW{L}'], vars(self)[f'db{L}'] = self._back_prop(dAL, current_cache, \"linear\")\n",
    "        for l in reversed(range(L-1)):\n",
    "            current_cache = caches[l]\n",
    "            vars(self)[f'dA{l}'] , vars(self)[f'dW{l+1}'], vars(self)[f'db{l+1}'] = self._back_prop(vars(self)[f'dA{l + 1}'], current_cache, activation = \"relu\")\n",
    "            \n",
    "\n",
    "    def update_parameters(self):\n",
    "        L = self.n_layers - 1\n",
    "        for l in range(L):\n",
    "            vars(self)[f'W{l+1}'] = vars(self)[f'W{l+1}'] - self.learning_rate * vars(self)[f'dW{l+1}']\n",
    "            vars(self)[f'b{l+1}']  = vars(self)[f'b{l+1}'] - self.learning_rate * vars(self)[f'db{l+1}']\n",
    "                \n",
    "\n",
    "    def fit(self, X_train, y_train, X_test=None, y_test=None, epochs=2000, print_cost=True):\n",
    "        X_train = X_train.T  # Transpose X_train to get the correct shape\n",
    "        if len(y_train.shape) == 1:  # Reshape Y_train if it's 1D\n",
    "            y_train = y_train.reshape(1, -1)\n",
    "\n",
    "        np.random.seed(1)\n",
    "        train_costs_mse = []  # To store training MSE costs\n",
    "        train_costs_mae = []  # To store training MAE costs\n",
    "        test_costs_mse = []  # To store testing MSE costs\n",
    "        test_costs_mae = []  # To store testing MAE costs (if testing data is provided)\n",
    "        m = X_train.shape[1]  # Number of training examples\n",
    "        self.initialize_parameters()  # Initialize parameters\n",
    "\n",
    "        # Gradient Descent Loop\n",
    "        for i in range(epochs):\n",
    "            if self.gd_type == 'batch':\n",
    "                # Batch Gradient Descent\n",
    "                predictions, caches = self.forward_prop(X_train)\n",
    "                train_mse, train_mae = self.compute_cost(predictions, y_train)\n",
    "                self.back_prop(predictions, y_train, caches)\n",
    "                self.update_parameters()\n",
    "\n",
    "            elif self.gd_type == 'stochastic':\n",
    "                # Stochastic Gradient Descent\n",
    "                for j in range(m):  # Loop over all examples\n",
    "                    x_single = X_train[:, j].reshape(-1, 1)  # Single example (column vector)\n",
    "                    y_single = y_train[:, j].reshape(1, -1)  # Corresponding label\n",
    "                    predictions, caches = self.forward_prop(x_single)\n",
    "                    train_mse, train_mae = self.compute_cost(predictions, y_single)\n",
    "                    self.back_prop(predictions, y_single, caches)\n",
    "                    self.update_parameters()\n",
    "\n",
    "            elif self.gd_type == 'minibatch':\n",
    "                # Mini-batch Gradient Descent\n",
    "                mini_batches = self.create_mini_batches(X_train, y_train, self.mini_batch_size)\n",
    "                for mini_batch in mini_batches:\n",
    "                    (X_mini, Y_mini) = mini_batch\n",
    "                    predictions, caches = self.forward_prop(X_mini)\n",
    "                    train_mse, train_mae = self.compute_cost(predictions, Y_mini)\n",
    "                    self.back_prop(predictions, Y_mini, caches)\n",
    "                    self.update_parameters()\n",
    "\n",
    "            # Store the training cost (MSE and MAE)\n",
    "            train_costs_mse.append(train_mse)\n",
    "            train_costs_mae.append(train_mae)\n",
    "\n",
    "            # Compute testing cost if testing data is provided\n",
    "            if X_test is not None and y_test is not None:\n",
    "                test_predictions, _ = self.forward_prop(X_test.T)\n",
    "                test_mse, test_mae = self.compute_cost(test_predictions, y_test.T)\n",
    "                test_costs_mse.append(test_mse)\n",
    "                test_costs_mae.append(test_mae)\n",
    "\n",
    "            # Print the cost every 500 epochs\n",
    "            if print_cost and i % 500 == 0:\n",
    "                if X_test is not None and y_test is not None:\n",
    "                    print(f\"Cost after iteration {i}: Train MSE = {train_mse}, Train MAE = {train_mae}, \"\n",
    "                          f\"Testing MSE = {test_mse}, Testing MAE = {test_mae}\")\n",
    "                else:\n",
    "                    print(f\"Cost after iteration {i}: Train MSE = {train_mse}, Train MAE = {train_mae}\")\n",
    "\n",
    "        return train_costs_mse, train_costs_mae, test_costs_mse, test_costs_mae\n",
    "\n",
    "    def create_mini_batches(self, X, Y, mini_batch_size):\n",
    "\n",
    "        m = X.shape[1]  # Number of examples\n",
    "        mini_batches = []\n",
    "        permutation = list(np.random.permutation(m))  # Randomize examples\n",
    "        shuffled_X = X[:, permutation]\n",
    "        shuffled_Y = Y[:, permutation]\n",
    "\n",
    "        num_complete_minibatches = m // mini_batch_size  # Number of full mini-batches\n",
    "        for k in range(num_complete_minibatches):\n",
    "            X_mini = shuffled_X[:, k * mini_batch_size:(k + 1) * mini_batch_size]\n",
    "            Y_mini = shuffled_Y[:, k * mini_batch_size:(k + 1) * mini_batch_size]\n",
    "            mini_batches.append((X_mini, Y_mini))\n",
    "\n",
    "        # Handle the last mini-batch (if size is less than mini_batch_size)\n",
    "        if m % mini_batch_size != 0:\n",
    "            X_mini = shuffled_X[:, num_complete_minibatches * mini_batch_size:]\n",
    "            Y_mini = shuffled_Y[:, num_complete_minibatches * mini_batch_size:]\n",
    "            mini_batches.append((X_mini, Y_mini))\n",
    "\n",
    "        return mini_batches            \n",
    "\n",
    "    def predict(self,X,y):\n",
    "\n",
    "        X = X.T\n",
    "        predictions, _ = self.forward_prop(X)\n",
    "        predictions = (predictions > 0.5)\n",
    "        predictions = np.squeeze(predictions.astype(int))\n",
    "        return np.sum((predictions == y)/X.shape[1]), predictions.T\n",
    "    \n",
    "    def compute_cost(self, predictions, y):\n",
    "\n",
    "        m = y.shape[0] \n",
    "\n",
    "        cost_mse = (1/m) * np.sum((predictions - y) ** 2)\n",
    "\n",
    "        cost_mae = (1/m) * np.sum(np.abs(predictions - y))\n",
    "\n",
    "        return cost_mse, cost_mae\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Model & Evaluasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3b213_row0_col0, #T_3b213_row0_col1, #T_3b213_row0_col2, #T_3b213_row0_col3, #T_3b213_row0_col4, #T_3b213_row0_col5, #T_3b213_row1_col0, #T_3b213_row1_col1, #T_3b213_row1_col2, #T_3b213_row1_col3, #T_3b213_row1_col4, #T_3b213_row1_col5, #T_3b213_row2_col0, #T_3b213_row2_col1, #T_3b213_row2_col2, #T_3b213_row2_col3, #T_3b213_row2_col4, #T_3b213_row2_col5 {\n",
       "  background-color: #f9f9f9;\n",
       "  border-color: black;\n",
       "  color: black;\n",
       "  border-style: solid;\n",
       "  border-width: 1px;\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3b213\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3b213_level0_col0\" class=\"col_heading level0 col0\" >Learning Rate</th>\n",
       "      <th id=\"T_3b213_level0_col1\" class=\"col_heading level0 col1\" >Epochs</th>\n",
       "      <th id=\"T_3b213_level0_col2\" class=\"col_heading level0 col2\" >GD Type</th>\n",
       "      <th id=\"T_3b213_level0_col3\" class=\"col_heading level0 col3\" >Mini Batch Size</th>\n",
       "      <th id=\"T_3b213_level0_col4\" class=\"col_heading level0 col4\" >Final Test MSE</th>\n",
       "      <th id=\"T_3b213_level0_col5\" class=\"col_heading level0 col5\" >Final Test MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3b213_level0_row0\" class=\"row_heading level0 row0\" >Batch</th>\n",
       "      <td id=\"T_3b213_row0_col0\" class=\"data row0 col0\" >0.000001</td>\n",
       "      <td id=\"T_3b213_row0_col1\" class=\"data row0 col1\" >50</td>\n",
       "      <td id=\"T_3b213_row0_col2\" class=\"data row0 col2\" >batch</td>\n",
       "      <td id=\"T_3b213_row0_col3\" class=\"data row0 col3\" >-</td>\n",
       "      <td id=\"T_3b213_row0_col4\" class=\"data row0 col4\" >1.458594</td>\n",
       "      <td id=\"T_3b213_row0_col5\" class=\"data row0 col5\" >0.937815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b213_level0_row1\" class=\"row_heading level0 row1\" >Stochastic</th>\n",
       "      <td id=\"T_3b213_row1_col0\" class=\"data row1 col0\" >0.000001</td>\n",
       "      <td id=\"T_3b213_row1_col1\" class=\"data row1 col1\" >50</td>\n",
       "      <td id=\"T_3b213_row1_col2\" class=\"data row1 col2\" >stochastic</td>\n",
       "      <td id=\"T_3b213_row1_col3\" class=\"data row1 col3\" >-</td>\n",
       "      <td id=\"T_3b213_row1_col4\" class=\"data row1 col4\" >1.460634</td>\n",
       "      <td id=\"T_3b213_row1_col5\" class=\"data row1 col5\" >0.937387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3b213_level0_row2\" class=\"row_heading level0 row2\" >Mini-batch</th>\n",
       "      <td id=\"T_3b213_row2_col0\" class=\"data row2 col0\" >0.000001</td>\n",
       "      <td id=\"T_3b213_row2_col1\" class=\"data row2 col1\" >50</td>\n",
       "      <td id=\"T_3b213_row2_col2\" class=\"data row2 col2\" >minibatch</td>\n",
       "      <td id=\"T_3b213_row2_col3\" class=\"data row2 col3\" >10</td>\n",
       "      <td id=\"T_3b213_row2_col4\" class=\"data row2 col4\" >1.479536</td>\n",
       "      <td id=\"T_3b213_row2_col5\" class=\"data row2 col5\" >0.935405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19f7a339350>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_compare(X_train, y_train, X_test, y_test, learning_rate, epochs, gd_type='batch', mini_batch_size=\"-\"):\n",
    "\n",
    "    model = neuralFunction(layer_dimensions=[10, 20, 15, 1], learning_rate=learning_rate, gd_type=gd_type, mini_batch_size=mini_batch_size)\n",
    "\n",
    "    # Train the model and get MSE and MAE losses\n",
    "    train_mse_losses, train_mae_losses, test_mse_losses, test_mae_losses = model.fit(X_train, y_train, X_test, y_test, epochs=epochs, print_cost=False)\n",
    "\n",
    "    # Return the final testing dataframe (MSE and MAE)\n",
    "    eval_data = pd.DataFrame([[learning_rate, epochs, gd_type, mini_batch_size, test_mse_losses[-1], test_mae_losses[-1]]],\n",
    "                             columns=['Learning Rate', 'Epochs', 'GD Type', 'Mini Batch Size', 'Final Test MSE', 'Final Test MAE'])\n",
    "    \n",
    "    return eval_data\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.000001\n",
    "epochs = 50\n",
    "\n",
    "# Train using Batch Gradient Descent\n",
    "results_batch = train_compare(X_train, y_train, X_test, y_test, learning_rate, epochs, gd_type='batch')\n",
    "results_batch.index = ['Batch']\n",
    "\n",
    "# Train using Stochastic Gradient Descent\n",
    "results_stochastic = train_compare(X_train, y_train, X_test, y_test, learning_rate, epochs, gd_type='stochastic')\n",
    "results_stochastic.index = ['Stochastic']\n",
    "\n",
    "# Train using Minibatch Gradient Descent\n",
    "results_minibatch = train_compare(X_train, y_train, X_test, y_test, learning_rate, epochs, gd_type='minibatch', mini_batch_size=10)\n",
    "results_minibatch.index = ['Mini-batch']\n",
    "\n",
    "# Combine results\n",
    "final_results = pd.concat([results_batch, results_stochastic, results_minibatch], ignore_index=False)\n",
    "\n",
    "# Apply simple style to the table\n",
    "styled_results = final_results.style.set_properties(**{\n",
    "    'background-color': '#f9f9f9',\n",
    "    'border-color': 'black',\n",
    "    'color': 'black',\n",
    "    'border-style': 'solid',\n",
    "    'border-width': '1px',\n",
    "    'text-align': 'center'\n",
    "})\n",
    "\n",
    "# Display styled table\n",
    "styled_results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
